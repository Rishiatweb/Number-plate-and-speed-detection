{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNrtNoteYaM2MYPpeIy8yNb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishiatweb/Number-plate-and-speed-detection/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "f7s2ZfUV4rou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2279f712-fece-447a-e4b1-ca640ede8c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-xvCjc1viDQ",
        "outputId": "c8b9e1d6-6b42-4e91-e6be-36f6db70e3af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset-df-dc.zip  drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import json\n",
        "\n",
        "# Define dataset ZIP file path (update this if needed)\n",
        "zip_filepath = \"/content/drive/MyDrive/dataset-df-dc.zip\"  # Change path if your file is elsewhere\n",
        "\n",
        "# Define extraction folder\n",
        "extract_folder = \"/content/dataset_extracted\"\n",
        "os.makedirs(extract_folder, exist_ok=True)\n",
        "\n",
        "# Step 1: Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_filepath, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "print(f\"Dataset extracted to: {extract_folder}\")\n",
        "\n",
        "# Step 2: Generate metadata.json\n",
        "metadata = {}\n",
        "\n",
        "# Iterate through extracted files\n",
        "for file_name in os.listdir(extract_folder):\n",
        "    file_path = os.path.join(extract_folder, file_name)\n",
        "\n",
        "    # Process only video files (common formats)\n",
        "    if file_name.lower().endswith((\".mp4\", \".avi\", \".mov\", \".mkv\")):\n",
        "        metadata[file_name] = {\n",
        "            \"label\": \"UNKNOWN\",  # Modify as needed\n",
        "            \"original\": None,     # Modify if deepfake mapping is known\n",
        "            \"split\": \"train\",     # Default to \"train\", modify if needed\n",
        "            \"actors\": []          # Add actor details if available\n",
        "        }\n",
        "\n",
        "# Step 3: Save metadata.json\n",
        "metadata_path = os.path.join(extract_folder, \"metadata.json\")\n",
        "with open(metadata_path, \"w\") as json_file:\n",
        "    json.dump(metadata, json_file, indent=4)\n",
        "\n",
        "print(f\"Metadata saved at: {metadata_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvDrZOLpSnvN",
        "outputId": "e47f0258-b932-462c-961f-4f5c59a54bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted to: /content/dataset_extracted\n",
            "Metadata saved at: /content/dataset_extracted/metadata.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sdE1j7c3ri1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df32d50f-a705-4e22-f1c2-2d4087e27888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing dataset at: /content/dataset_extracted/dataset-df-dc-tarini\n",
            "Loading dataset...\n",
            "Fake videos: 322, Real videos: 77\n",
            "Training model...\n",
            "Video errocgcham.mp4: 37 sequences\n",
            "Video caifxvsozs.mp4: 37 sequences\n",
            "Epoch 1/5\n",
            "\u001b[1m  36/1147\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 49ms/step - accuracy: 0.7308 - loss: 0.5758Memory usage: 2517.86 MB\n",
            "\u001b[1m  38/1147\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 48ms/step - accuracy: 0.7407 - loss: 0.5585Video deywhkarol.mp4: 37 sequences\n",
            "Memory usage: 2642.68 MB\n",
            "\u001b[1m  39/1147\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 112ms/step - accuracy: 0.7453 - loss: 0.5502Video bxzakyopjf.mp4: 37 sequences\n",
            "\u001b[1m  74/1147\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:13\u001b[0m 124ms/step - accuracy: 0.7983 - loss: 0.4634Memory usage: 2718.17 MB\n",
            "\u001b[1m  76/1147\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 122ms/step - accuracy: 0.8004 - loss: 0.4607Video agdkmztvby.mp4: 37 sequences\n",
            "Memory usage: 2751.63 MB\n",
            "\u001b[1m  77/1147\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:55\u001b[0m 164ms/step - accuracy: 0.8014 - loss: 0.4595Video ehccixxzoe.mp4: 37 sequences\n",
            "\u001b[1m 110/1147\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 151ms/step - accuracy: 0.8047 - loss: 0.4502Memory usage: 2782.96 MB\n",
            "\u001b[1m 114/1147\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:32\u001b[0m 148ms/step - accuracy: 0.8045 - loss: 0.4505Video bmehkyanbj.mp4: 37 sequences\n",
            "Memory usage: 2787.66 MB\n",
            "\u001b[1m 115/1147\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:52\u001b[0m 167ms/step - accuracy: 0.8044 - loss: 0.4506Video egghxjjmfg.mp4: 37 sequences\n",
            "\u001b[1m 143/1147\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:51\u001b[0m 171ms/step - accuracy: 0.8045 - loss: 0.4538Memory usage: 2896.26 MB\n",
            "\u001b[1m 152/1147\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:43\u001b[0m 164ms/step - accuracy: 0.8058 - loss: 0.4541Video esxrvsgpvb.mp4: 37 sequences\n",
            "Memory usage: 2893.77 MB\n",
            "\u001b[1m 153/1147\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:54\u001b[0m 175ms/step - accuracy: 0.8060 - loss: 0.4542Video cpjxareypw.mp4: 37 sequences\n",
            "\u001b[1m 174/1147\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:48\u001b[0m 174ms/step - accuracy: 0.8062 - loss: 0.4573Memory usage: 2912.34 MB\n",
            "\u001b[1m 190/1147\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:36\u001b[0m 163ms/step - accuracy: 0.8067 - loss: 0.4589Video btugrnoton.mp4: 37 sequences\n",
            "Memory usage: 2910.63 MB\n",
            "\u001b[1m 191/1147\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 173ms/step - accuracy: 0.8068 - loss: 0.4589Video ckjaibzfxa.mp4: 37 sequences\n",
            "\u001b[1m 196/1147\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 182ms/step - accuracy: 0.8069 - loss: 0.4593Memory usage: 2940.85 MB\n",
            "\u001b[1m 228/1147\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:31\u001b[0m 164ms/step - accuracy: 0.8100 - loss: 0.4586Video ayqvfdhslr.mp4: 37 sequences\n",
            "Memory usage: 2946.63 MB\n",
            "\u001b[1m 229/1147\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 171ms/step - accuracy: 0.8101 - loss: 0.4586Video cobjrlugvp.mp4: 37 sequences\n",
            "\u001b[1m 231/1147\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 181ms/step - accuracy: 0.8103 - loss: 0.4586Memory usage: 2957.16 MB\n",
            "\u001b[1m 266/1147\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:24\u001b[0m 164ms/step - accuracy: 0.8128 - loss: 0.4601Video dxuplhwvig.mp4: 37 sequences\n",
            "Memory usage: 2925.16 MB\n",
            "\u001b[1m 267/1147\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:26\u001b[0m 167ms/step - accuracy: 0.8129 - loss: 0.4601Video chviwxsfhg.mp4: 37 sequences\n",
            "\u001b[1m 269/1147\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:34\u001b[0m 176ms/step - accuracy: 0.8130 - loss: 0.4602Memory usage: 2945.73 MB\n",
            "\u001b[1m 304/1147\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:16\u001b[0m 162ms/step - accuracy: 0.8119 - loss: 0.4627Video cgvrgibpfo.mp4: 37 sequences\n",
            "Memory usage: 2939.87 MB\n",
            "\u001b[1m 305/1147\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:21\u001b[0m 169ms/step - accuracy: 0.8118 - loss: 0.4628Video bzythlfnhq.mp4: 37 sequences\n",
            "\u001b[1m 308/1147\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:26\u001b[0m 175ms/step - accuracy: 0.8115 - loss: 0.4632Memory usage: 2952.46 MB\n",
            "\u001b[1m 342/1147\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:10\u001b[0m 162ms/step - accuracy: 0.8063 - loss: 0.4677Video bjkmjilrxp.mp4: 37 sequences\n",
            "Memory usage: 2934.95 MB\n",
            "\u001b[1m 343/1147\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:12\u001b[0m 165ms/step - accuracy: 0.8062 - loss: 0.4679Video edyncaijwx.mp4: 37 sequences\n",
            "\u001b[1m 345/1147\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 172ms/step - accuracy: 0.8058 - loss: 0.4682Memory usage: 2954.60 MB\n",
            "\u001b[1m 380/1147\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 161ms/step - accuracy: 0.7979 - loss: 0.4737Video dkdwxmtpuo.mp4: 37 sequences\n",
            "Memory usage: 2924.77 MB\n",
            "\u001b[1m 381/1147\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 164ms/step - accuracy: 0.7976 - loss: 0.4739Video brwrlczjvi.mp4: 37 sequences\n",
            "\u001b[1m 383/1147\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:11\u001b[0m 172ms/step - accuracy: 0.7971 - loss: 0.4742Memory usage: 2966.88 MB\n",
            "\u001b[1m 418/1147\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 162ms/step - accuracy: 0.7854 - loss: 0.4801Video dboxtiehng.mp4: 37 sequences\n",
            "Memory usage: 2927.03 MB\n",
            "\u001b[1m 419/1147\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 164ms/step - accuracy: 0.7850 - loss: 0.4803Video dhxctgyoqj.mp4: 37 sequences\n",
            "\u001b[1m 421/1147\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:02\u001b[0m 169ms/step - accuracy: 0.7843 - loss: 0.4806Memory usage: 2975.27 MB\n",
            "\u001b[1m 456/1147\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50\u001b[0m 160ms/step - accuracy: 0.7704 - loss: 0.4865Video axczxisdtb.mp4: 37 sequences\n",
            "Memory usage: 2927.26 MB\n",
            "\u001b[1m 457/1147\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 163ms/step - accuracy: 0.7700 - loss: 0.4867Video bwhlgysghg.mp4: 37 sequences\n",
            "\u001b[1m 460/1147\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 170ms/step - accuracy: 0.7688 - loss: 0.4872Memory usage: 2937.36 MB\n",
            "\u001b[1m 493/1147\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:46\u001b[0m 162ms/step - accuracy: 0.7579 - loss: 0.4925Video cxfujlvsuw.mp4: 37 sequences\n",
            "Memory usage: 2935.16 MB\n",
            "\u001b[1m 495/1147\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:47\u001b[0m 165ms/step - accuracy: 0.7574 - loss: 0.4928Video eckvhdusax.mp4: 37 sequences\n",
            "\u001b[1m 497/1147\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:49\u001b[0m 168ms/step - accuracy: 0.7568 - loss: 0.4931Memory usage: 2949.41 MB\n",
            "\u001b[1m 532/1147\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 161ms/step - accuracy: 0.7475 - loss: 0.4983Video byijojkdba.mp4: 37 sequences\n",
            "Memory usage: 2930.79 MB\n",
            "\u001b[1m 533/1147\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:39\u001b[0m 163ms/step - accuracy: 0.7472 - loss: 0.4984Video bmjzrlszhi.mp4: 37 sequences\n",
            "\u001b[1m 536/1147\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 167ms/step - accuracy: 0.7464 - loss: 0.4989Memory usage: 2951.16 MB\n",
            "\u001b[1m 570/1147\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:32\u001b[0m 161ms/step - accuracy: 0.7379 - loss: 0.5039Video dafhtipaml.mp4: 37 sequences\n",
            "Memory usage: 2925.66 MB\n",
            "\u001b[1m 571/1147\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 164ms/step - accuracy: 0.7377 - loss: 0.5040Video abarnvbtwb.mp4: 37 sequences\n",
            "\u001b[1m 573/1147\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:36\u001b[0m 168ms/step - accuracy: 0.7372 - loss: 0.5043Memory usage: 2943.69 MB\n",
            "\u001b[1m 608/1147\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:26\u001b[0m 161ms/step - accuracy: 0.7290 - loss: 0.5092Video ehbnclaukr.mp4: 37 sequences\n",
            "Memory usage: 2904.06 MB\n",
            "\u001b[1m 609/1147\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 162ms/step - accuracy: 0.7287 - loss: 0.5093Video cizlkenljw.mp4: 37 sequences\n",
            "\u001b[1m 611/1147\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 165ms/step - accuracy: 0.7282 - loss: 0.5096Memory usage: 2970.45 MB\n",
            "\u001b[1m 646/1147\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 160ms/step - accuracy: 0.7196 - loss: 0.5143Video ehieahnhte.mp4: 37 sequences\n",
            "Memory usage: 2974.71 MB\n",
            "\u001b[1m 647/1147\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 162ms/step - accuracy: 0.7193 - loss: 0.5144Video ajqslcypsw.mp4: 37 sequences\n",
            "\u001b[1m 649/1147\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 166ms/step - accuracy: 0.7188 - loss: 0.5147Memory usage: 2964.21 MB\n",
            "\u001b[1m 684/1147\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:14\u001b[0m 161ms/step - accuracy: 0.7096 - loss: 0.5191Video agqphdxmwt.mp4: 37 sequences\n",
            "Memory usage: 2960.04 MB\n",
            "\u001b[1m 685/1147\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:14\u001b[0m 162ms/step - accuracy: 0.7093 - loss: 0.5193Video efwfxwwlbw.mp4: 37 sequences\n",
            "\u001b[1m 687/1147\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:15\u001b[0m 165ms/step - accuracy: 0.7088 - loss: 0.5195Memory usage: 2984.05 MB\n",
            "\u001b[1m 722/1147\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 159ms/step - accuracy: 0.6991 - loss: 0.5238Video ehdkmxgtxh.mp4: 37 sequences\n",
            "Memory usage: 2984.05 MB\n",
            "\u001b[1m 723/1147\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 160ms/step - accuracy: 0.6988 - loss: 0.5239Video djxdyjopjd.mp4: 37 sequences\n",
            "\u001b[1m 725/1147\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 165ms/step - accuracy: 0.6983 - loss: 0.5241Memory usage: 2990.66 MB\n",
            "\u001b[1m 760/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:01\u001b[0m 160ms/step - accuracy: 0.6884 - loss: 0.5281Video bgmlwsoamc.mp4: 37 sequences\n",
            "Memory usage: 2948.66 MB\n",
            "\u001b[1m 761/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:02\u001b[0m 161ms/step - accuracy: 0.6881 - loss: 0.5283Video dsjbknkujw.mp4: 37 sequences\n",
            "\u001b[1m 763/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:03\u001b[0m 164ms/step - accuracy: 0.6875 - loss: 0.5285Memory usage: 2962.52 MB\n",
            "\u001b[1m 798/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 160ms/step - accuracy: 0.6776 - loss: 0.5323Video bmjmjmbglm.mp4: 37 sequences\n",
            "Memory usage: 2932.83 MB\n",
            "\u001b[1m 799/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m55s\u001b[0m 161ms/step - accuracy: 0.6773 - loss: 0.5324Video cfxkpiweqt.mp4: 37 sequences\n",
            "\u001b[1m 803/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 165ms/step - accuracy: 0.6761 - loss: 0.5328Memory usage: 2956.71 MB\n",
            "\u001b[1m 836/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 160ms/step - accuracy: 0.6667 - loss: 0.5363Video dubiroskqn.mp4: 37 sequences\n",
            "Memory usage: 2932.83 MB\n",
            "\u001b[1m 837/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 162ms/step - accuracy: 0.6665 - loss: 0.5364Video erlvuvjsjf.mp4: 37 sequences\n",
            "\u001b[1m 839/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 164ms/step - accuracy: 0.6659 - loss: 0.5366Memory usage: 2964.12 MB\n",
            "\u001b[1m 874/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m43s\u001b[0m 160ms/step - accuracy: 0.6560 - loss: 0.5400Video abqwwspghj.mp4: 37 sequences\n",
            "Memory usage: 2951.51 MB\n",
            "\u001b[1m 875/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m43s\u001b[0m 161ms/step - accuracy: 0.6557 - loss: 0.5401Video bpapbctoao.mp4: 37 sequences\n",
            "\u001b[1m 877/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m43s\u001b[0m 163ms/step - accuracy: 0.6552 - loss: 0.5403Memory usage: 2993.39 MB\n",
            "\u001b[1m 912/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m37s\u001b[0m 159ms/step - accuracy: 0.6454 - loss: 0.5436Video btunxncpjh.mp4: 37 sequences\n",
            "Memory usage: 2966.89 MB\n",
            "\u001b[1m 913/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m37s\u001b[0m 161ms/step - accuracy: 0.6452 - loss: 0.5437Video cprhtltsjp.mp4: 37 sequences\n",
            "\u001b[1m 915/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m37s\u001b[0m 164ms/step - accuracy: 0.6446 - loss: 0.5439Memory usage: 3017.39 MB\n",
            "\u001b[1m 949/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m31s\u001b[0m 160ms/step - accuracy: 0.6353 - loss: 0.5469Video emfbhytfhc.mp4: 37 sequences\n",
            "Memory usage: 3009.45 MB\n",
            "\u001b[1m 951/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m31s\u001b[0m 161ms/step - accuracy: 0.6348 - loss: 0.5471Video bgwmmujlmc.mp4: 37 sequences\n",
            "\u001b[1m 953/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m31s\u001b[0m 163ms/step - accuracy: 0.6342 - loss: 0.5473Memory usage: 3002.15 MB\n",
            "\u001b[1m 988/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m25s\u001b[0m 160ms/step - accuracy: 0.6249 - loss: 0.5503Video cbbibzcoih.mp4: 37 sequences\n",
            "Memory usage: 3002.15 MB\n",
            "\u001b[1m 989/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m25s\u001b[0m 162ms/step - accuracy: 0.6246 - loss: 0.5504Video ahqqqilsxt.mp4: 37 sequences\n",
            "\u001b[1m 991/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m25s\u001b[0m 165ms/step - accuracy: 0.6241 - loss: 0.5505Memory usage: 2985.57 MB\n",
            "\u001b[1m1025/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m19s\u001b[0m 161ms/step - accuracy: 0.6152 - loss: 0.5533Video altziddtxi.mp4: 37 sequences\n",
            "Memory usage: 2954.38 MB\n",
            "\u001b[1m1027/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m19s\u001b[0m 162ms/step - accuracy: 0.6147 - loss: 0.5535Video atkdltyyen.mp4: 37 sequences\n",
            "\u001b[1m1029/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m19s\u001b[0m 164ms/step - accuracy: 0.6142 - loss: 0.5536Memory usage: 2984.51 MB\n",
            "\u001b[1m1063/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13s\u001b[0m 161ms/step - accuracy: 0.6055 - loss: 0.5563Video cyclgfjdrv.mp4: 37 sequences\n",
            "Memory usage: 2918.64 MB\n",
            "\u001b[1m1065/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13s\u001b[0m 162ms/step - accuracy: 0.6050 - loss: 0.5564Video cppdvdejkc.mp4: 37 sequences\n",
            "\u001b[1m1067/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13s\u001b[0m 165ms/step - accuracy: 0.6045 - loss: 0.5566Memory usage: 2987.53 MB\n",
            "\u001b[1m1102/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - accuracy: 0.5958 - loss: 0.5592Video dfbpceeaox.mp4: 37 sequences\n",
            "Memory usage: 2945.55 MB\n",
            "\u001b[1m1103/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - accuracy: 0.5956 - loss: 0.5592Video ccfoszqabv.mp4: 37 sequences\n",
            "\u001b[1m1105/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - accuracy: 0.5951 - loss: 0.5594Memory usage: 2942.11 MB\n",
            "\u001b[1m1140/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 160ms/step - accuracy: 0.5866 - loss: 0.5619Video bkmdzhfzfh.mp4: 37 sequences\n",
            "Memory usage: 2894.11 MB\n",
            "\u001b[1m1141/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.5864 - loss: 0.5620Video ciyoudyhly.mp4: 37 sequences\n",
            "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.5850 - loss: 0.5624Video dsgpbgsrdm.mp4: 37 sequences\n",
            "Video bulkxhhknf.mp4: 37 sequences\n",
            "Memory usage: 2774.97 MB\n",
            "Video cycacemkmt.mp4: 37 sequences\n",
            "Memory usage: 2909.91 MB\n",
            "Video dhcndnuwta.mp4: 37 sequences\n",
            "Memory usage: 2944.94 MB\n",
            "Video adylbeequz.mp4: 37 sequences\n",
            "Memory usage: 3018.11 MB\n",
            "Video dakiztgtnw.mp4: 37 sequences\n",
            "Memory usage: 3021.05 MB\n",
            "Video drtbksnpol.mp4: 37 sequences\n",
            "Memory usage: 3050.61 MB\n",
            "Video cyxlcuyznd.mp4: 37 sequences\n",
            "Memory usage: 3083.11 MB\n",
            "Video bctvsmddgq.mp4: 37 sequences\n",
            "Memory usage: 3107.32 MB\n",
            "Video ellavthztb.mp4: 37 sequences\n",
            "Memory usage: 3134.56 MB\n",
            "Video cwrtyzndpx.mp4: 37 sequences\n",
            "Memory usage: 3134.77 MB\n",
            "Video dkuayagnmc.mp4: 37 sequences\n",
            "Memory usage: 3180.71 MB\n",
            "Video bvgwelbeof.mp4: 37 sequences\n",
            "Memory usage: 3180.47 MB\n",
            "Video eggbjzxnmg.mp4: 37 sequences\n",
            "Memory usage: 3171.14 MB\n",
            "Video aczrgyricp.mp4: 37 sequences\n",
            "Memory usage: 3171.79 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video atvmxvwyns.mp4: 37 sequences\n",
            "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 209ms/step - accuracy: 0.5847 - loss: 0.5624 - val_accuracy: 0.5019 - val_loss: 0.6931\n",
            "Epoch 2/5\n",
            "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 123us/step - accuracy: 0.5004 - loss: 0.7039 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
            "Epoch 4/5\n",
            "\u001b[1m1147/1147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103us/step - accuracy: 0.5004 - loss: 0.6986 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Model saved as 'deepfake_detector_final.keras'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8507d790-b81b-47d9-af42-08f9ad6179b0\", \"deepfake_detector_final.keras\", 403835030)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, TimeDistributed\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "import psutil\n",
        "\n",
        "\n",
        "# Enable GPU memory growth (Colab-specific)\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "def print_memory_usage():\n",
        "    mem = psutil.Process().memory_info().rss / 1024**2\n",
        "    print(f\"Memory usage: {mem:.2f} MB\")\n",
        "\n",
        "# --- Data Loading and Preprocessing Module ---\n",
        "class DataLoader:\n",
        "    def __init__(self, dataset_path, sequence_length=8, frame_size=(128, 128)):\n",
        "        self.dataset_path = dataset_path\n",
        "        self.sequence_length = sequence_length\n",
        "        self.frame_size = frame_size\n",
        "        self.metadata = self.load_metadata()\n",
        "\n",
        "    def load_metadata(self):\n",
        "        \"\"\"Load metadata.json to get video labels.\"\"\"\n",
        "        metadata_path = os.path.join(self.dataset_path, '/content/dataset_extracted/metadata.json')\n",
        "        with open(metadata_path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def extract_frames(self, video_path):\n",
        "        \"\"\"Extract frames from a video and resize them.\"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frames = []\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = cv2.resize(frame, self.frame_size)\n",
        "            frame = frame / 255.0  # Normalize to [0, 1]\n",
        "            frames.append(frame)\n",
        "        cap.release()\n",
        "        #print(f\"Extracted {len(frames)} frames from {video_path}\")\n",
        "        return np.array(frames)\n",
        "\n",
        "    def load_data_from_subfolder(self, subfolder_path, label, max_videos=20):\n",
        "           \"\"\"Loads data from a specific subfolder (fake_videos or real_videos).\"\"\"\n",
        "           X, y = [], []\n",
        "           video_files = [f for f in os.listdir(subfolder_path) if f.endswith('.mp4')]\n",
        "           for idx, video_file in enumerate(video_files[:max_videos]):\n",
        "               video_path = os.path.join(subfolder_path, video_file)\n",
        "               try:\n",
        "                frames = self.extract_frames(video_path)\n",
        "                sequences = self.create_sequences(frames)\n",
        "                print(f\"Video {idx + 1}: {len(sequences)} sequences\")\n",
        "                for seq in sequences:\n",
        "                   X.append(seq)\n",
        "                   y.append(label)\n",
        "                print_memory_usage()\n",
        "               except Exception as e:\n",
        "                print(f\"Error with {video_file}: {e}\")\n",
        "           X_np = np.array(X)\n",
        "           y_np = np.array(y)\n",
        "           #print(f\"Subfolder {subfolder_path}: X shape {.shape}, y shape {y_np.shape}\")\n",
        "           return X_np, y_np\n",
        "\n",
        "    def create_sequences(self, frames):\n",
        "        \"\"\"Split frames into sequences of fixed length.\"\"\"\n",
        "        if len(frames) < self.sequence_length:\n",
        "            return []  # Skip if too short\n",
        "        sequences = []\n",
        "        for i in range(0, len(frames) - self.sequence_length + 1, self.sequence_length):\n",
        "            seq = frames[i:i + self.sequence_length]\n",
        "            sequences.append(seq)\n",
        "        return sequences\n",
        "\n",
        "    def load_dataset(self, max_videos=100):\n",
        "        \"\"\"Load videos and generate labeled sequences.\"\"\"\n",
        "        X, y = [], []\n",
        "        video_files = [f for f in os.listdir(self.dataset_path) if f.endswith('.mp4')]\n",
        "\n",
        "        for idx, video_file in enumerate(video_files[:max_videos]):  # Limit for testing\n",
        "            video_path = os.path.join(self.dataset_path, video_file)\n",
        "            label = 1 if self.metadata.get(video_file, {}).get('label') == 'FAKE' else 0\n",
        "            frames = self.extract_frames(video_path)\n",
        "            sequences = self.create_sequences(frames)\n",
        "\n",
        "            for seq in sequences:\n",
        "                X.append(seq)\n",
        "                y.append(label)\n",
        "            print(f\"Processed video {idx + 1}/{min(max_videos, len(video_files))}\")\n",
        "\n",
        "        return np.array(X), np.array(y)\n",
        "    def data_generator(self, subfolder_path, label, max_videos=20, batch_size=2):\n",
        "        video_files = [f for f in os.listdir(subfolder_path) if f.endswith('.mp4')]\n",
        "        for idx, video_file in enumerate(video_files[:max_videos]):\n",
        "            video_path = os.path.join(subfolder_path, video_file)\n",
        "            try:\n",
        "                frames = self.extract_frames(video_path)\n",
        "                sequences = self.create_sequences(frames)\n",
        "                print(f\"Video {idx + 1}: {len(sequences)} sequences\")\n",
        "                for i in range(0, len(sequences), batch_size):\n",
        "                    batch_seq = sequences[i:i + batch_size]\n",
        "                    yield np.array(batch_seq), np.array([label] * len(batch_seq))\n",
        "                print_memory_usage()\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {video_file}: {e}\")\n",
        "\n",
        "# --- Model Definition Module ---\n",
        "class DeepfakeDetector:\n",
        "    def __init__(self, sequence_length=16, frame_size=(224, 224)):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.frame_size = frame_size\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"Build a CNN-LSTM model for temporal inconsistency detection.\"\"\"\n",
        "        model = Sequential([\n",
        "            # CNN for spatial feature extraction\n",
        "            TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "                           input_shape=(self.sequence_length, *self.frame_size, 3)),\n",
        "            TimeDistributed(MaxPooling2D((2, 2))),\n",
        "            TimeDistributed(Conv2D(64, (3, 3), activation='relu', padding='same')),\n",
        "            TimeDistributed(MaxPooling2D((2, 2))),\n",
        "            TimeDistributed(Flatten()),\n",
        "            # LSTM for temporal analysis\n",
        "            LSTM(128, return_sequences=False),\n",
        "            Dense(64, activation='relu'),\n",
        "            Dense(1, activation='sigmoid')  # Binary output: real (0) or fake (1)\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def train_generator(self, train_gen, val_gen, steps_per_epoch, validation_steps, epochs=5):\n",
        "        checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy')\n",
        "        early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "        history = self.model.fit(\n",
        "            train_gen, steps_per_epoch=steps_per_epoch,\n",
        "            validation_data=val_gen, validation_steps=validation_steps,\n",
        "            epochs=epochs, callbacks=[checkpoint, early_stop]\n",
        "        )\n",
        "        return history\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict on new data.\"\"\"\n",
        "        return self.model.predict(X)\n",
        "\n",
        "# --- Main Execution ---\n",
        "\n",
        "def main():\n",
        "    # Step 1: Use existing dataset in Colab\n",
        "    dataset_path = '/content/dataset_extracted/dataset-df-dc-tarini'\n",
        "    print(\"Using existing dataset at:\", dataset_path)\n",
        "\n",
        "    # Step 2: Load and preprocess data with generators\n",
        "    print(\"Loading dataset...\")\n",
        "    loader = DataLoader(dataset_path, sequence_length=8, frame_size=(128, 128))\n",
        "\n",
        "    # Get video files\n",
        "    fake_videos = [f for f in os.listdir(os.path.join(dataset_path, 'fake_videos')) if f.endswith('.mp4')]\n",
        "    real_videos = [f for f in os.listdir(os.path.join(dataset_path, 'real_videos')) if f.endswith('.mp4')]\n",
        "    print(f\"Fake videos: {len(fake_videos)}, Real videos: {len(real_videos)}\")\n",
        "\n",
        "    # Balance dataset: sample 77 fake videos to match real\n",
        "    import random\n",
        "    random.seed(42)  # For reproducibility\n",
        "    fake_videos_sampled = random.sample(fake_videos, 77)  # Downsample fake to match real\n",
        "\n",
        "    # Split: 80% train (62), 20% val (15) per class\n",
        "    train_fake_videos = fake_videos_sampled[:62]\n",
        "    val_fake_videos = fake_videos_sampled[62:77]\n",
        "    train_real_videos = real_videos[:62]\n",
        "    val_real_videos = real_videos[62:77]\n",
        "\n",
        "    # Generators with explicit video lists\n",
        "    def video_generator(subfolder_path, video_list, label, batch_size=2):\n",
        "        for video_file in video_list:\n",
        "            video_path = os.path.join(subfolder_path, video_file)\n",
        "            try:\n",
        "                frames = loader.extract_frames(video_path)\n",
        "                sequences = loader.create_sequences(frames)\n",
        "                print(f\"Video {video_file}: {len(sequences)} sequences\")\n",
        "                for i in range(0, len(sequences), batch_size):\n",
        "                    batch_seq = sequences[i:i + batch_size]\n",
        "                    yield np.array(batch_seq), np.array([label] * len(batch_seq))\n",
        "                print_memory_usage()\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {video_file}: {e}\")\n",
        "\n",
        "    train_fake_gen = video_generator(os.path.join(dataset_path, 'fake_videos'), train_fake_videos, label=1)\n",
        "    train_real_gen = video_generator(os.path.join(dataset_path, 'real_videos'), train_real_videos, label=0)\n",
        "    val_fake_gen = video_generator(os.path.join(dataset_path, 'fake_videos'), val_fake_videos, label=1)\n",
        "    val_real_gen = video_generator(os.path.join(dataset_path, 'real_videos'), val_real_videos, label=0)\n",
        "\n",
        "    # Combine generators with finite iteration\n",
        "    def combined_generator(gen1, gen2, total_steps):\n",
        "        steps = 0\n",
        "        iter1, iter2 = iter(gen1), iter(gen2)\n",
        "        while steps < total_steps:\n",
        "            try:\n",
        "                yield next(iter1)\n",
        "                steps += 1\n",
        "                if steps >= total_steps:\n",
        "                    break\n",
        "                yield next(iter2)\n",
        "                steps += 1\n",
        "            except StopIteration:\n",
        "                print(\"One generator exhausted early\")\n",
        "                break\n",
        "\n",
        "    # Steps: 37 sequences per video, batch_size=2\n",
        "    steps_per_epoch = (62 * 37) // 2  # 62 videos x 37 sequences = 2294 sequences, 1147 batches\n",
        "    validation_steps = (15 * 37) // 2  # 15 videos x 37 sequences = 555 sequences, 277 batches\n",
        "\n",
        "    train_gen = combined_generator(train_fake_gen, train_real_gen, steps_per_epoch)\n",
        "    val_gen = combined_generator(val_fake_gen, val_real_gen, validation_steps)\n",
        "\n",
        "    # Step 3: Initialize and train model\n",
        "    detector = DeepfakeDetector(sequence_length=8, frame_size=(128, 128))\n",
        "    print(\"Training model...\")\n",
        "    history = detector.train_generator(train_gen, val_gen, steps_per_epoch, validation_steps, epochs=5)\n",
        "\n",
        "    # Step 4: Save and download the model\n",
        "    detector.model.save('deepfake_detector_final.keras')  # Using .keras format\n",
        "    print(\"Model saved as 'deepfake_detector_final.keras'\")\n",
        "    files.download('deepfake_detector_final.keras')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Step 1: Upload and unzip dataset in Colab\n",
        "    print(\"Upload the dataset ZIP file:\")\n",
        "    dataset_path = '/content/dataset_extracted/dataset-df-dc-tarini'\n",
        "\n",
        "    # Step 2: Load and preprocess data with generators\n",
        "    print(\"Loading dataset...\")\n",
        "    loader = DataLoader(dataset_path, sequence_length=8, frame_size=(128, 128))\n",
        "\n",
        "    # Generators: 16 train, 4 val per class\n",
        "    train_fake_gen = loader.data_generator(os.path.join(dataset_path, 'fake_videos'), label=1, max_videos=16)\n",
        "    train_real_gen = loader.data_generator(os.path.join(dataset_path, 'real_videos'), label=0, max_videos=16)\n",
        "    val_fake_gen = loader.data_generator(os.path.join(dataset_path, 'fake_videos'), label=1, max_videos=4)\n",
        "    val_real_gen = loader.data_generator(os.path.join(dataset_path, 'real_videos'), label=0, max_videos=4)\n",
        "\n",
        "    # Combine generators\n",
        "    def combined_generator(gen1, gen2):\n",
        "        while True:\n",
        "            yield next(gen1)\n",
        "            yield next(gen2)\n",
        "\n",
        "    train_gen = combined_generator(train_fake_gen, train_real_gen)\n",
        "    val_gen = combined_generator(val_fake_gen, val_real_gen)\n",
        "\n",
        "    # Steps: 37 sequences per video, batch_size=2\n",
        "    steps_per_epoch = (16 * 37) // 2  # 16 videos per class\n",
        "    validation_steps = (4 * 37) // 2  # 4 videos per class\n",
        "\n",
        "    # Step 3: Initialize and train model\n",
        "    detector = DeepfakeDetector(sequence_length=8, frame_size=(128, 128))\n",
        "    print(\"Training model...\")\n",
        "    history = detector.train_generator(train_gen, val_gen, steps_per_epoch, validation_steps, epochs=5)\n",
        "\n",
        "    # Step 4: Save and download the model\n",
        "    detector.model.save('deepfake_detector_final.h5')\n",
        "    print(\"Model saved as 'deepfake_detector_final.h5'\")\n",
        "    files.download('deepfake_detector_final.h5')"
      ],
      "metadata": {
        "id": "WLPrEGrGs5vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "\n",
        "def print_memory_usage():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    mem = process.memory_info().rss / 1024**2  # MB\n",
        "    print(f\"Memory usage: {mem:.2f} MB\")\n",
        "print_memory_usage()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z_9i1kPjrt1",
        "outputId": "95d93c82-5d38-4ca5-b1fd-9d08f54e574c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage: 887.04 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/dataset_extracted/"
      ],
      "metadata": {
        "id": "5P9oH9qPgSVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "num_fake_videos = len([f for f in os.listdir('/content/dataset_extracted/dataset-df-dc-tarini/fake_videos') if f.endswith('.mp4')])\n",
        "num_real_videos = len([f for f in os.listdir('/content/dataset_extracted/dataset-df-dc-tarini/real_videos') if f.endswith('.mp4')])\n",
        "print(f\"Number of fake videos: {num_fake_videos}\")\n",
        "print(f\"Number of real videos: {num_real_videos}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkvaqW1VgoVH",
        "outputId": "6bf14abc-dcd0-4adc-98e7-b9f84d659602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of fake videos: 322\n",
            "Number of real videos: 77\n"
          ]
        }
      ]
    }
  ]
}